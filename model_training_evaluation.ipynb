{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c756ab62",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.018064,
     "end_time": "2023-05-17T17:47:20.413380",
     "exception": false,
     "start_time": "2023-05-17T17:47:20.395316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/impoxeur2001/Sentiment_Analysis_Darija/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8d7b3",
   "metadata": {
    "id": "sormdm-7X0yi",
    "papermill": {
     "duration": 0.017146,
     "end_time": "2023-05-17T17:47:20.447391",
     "exception": false,
     "start_time": "2023-05-17T17:47:20.430245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**NOTEBOOK SETUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e336ab05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:20.484244Z",
     "iopub.status.busy": "2023-05-17T17:47:20.483419Z",
     "iopub.status.idle": "2023-05-17T17:47:33.230231Z",
     "shell.execute_reply": "2023-05-17T17:47:33.228876Z"
    },
    "id": "5_gbEPiWO5-N",
    "outputId": "c46d176f-69ad-4e92-e673-7f868d9cf6eb",
    "papermill": {
     "duration": 12.767895,
     "end_time": "2023-05-17T17:47:33.232635",
     "exception": false,
     "start_time": "2023-05-17T17:47:20.464740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3567b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:33.276726Z",
     "iopub.status.busy": "2023-05-17T17:47:33.276394Z",
     "iopub.status.idle": "2023-05-17T17:47:44.930730Z",
     "shell.execute_reply": "2023-05-17T17:47:44.929251Z"
    },
    "id": "gcLJB8xNUNCM",
    "outputId": "d97a6e9f-0827-425e-b27c-d09ff10dd56e",
    "papermill": {
     "duration": 11.67575,
     "end_time": "2023-05-17T17:47:44.933110",
     "exception": false,
     "start_time": "2023-05-17T17:47:33.257360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarabic in /opt/conda/lib/python3.10/site-packages (0.6.15)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from pyarabic) (1.16.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fcc941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:44.971519Z",
     "iopub.status.busy": "2023-05-17T17:47:44.971206Z",
     "iopub.status.idle": "2023-05-17T17:47:59.659032Z",
     "shell.execute_reply": "2023-05-17T17:47:59.657891Z"
    },
    "id": "WD-Wo0E6eD7m",
    "papermill": {
     "duration": 14.710063,
     "end_time": "2023-05-17T17:47:59.661738",
     "exception": false,
     "start_time": "2023-05-17T17:47:44.951675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from operator import length_hint \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0205909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.701131Z",
     "iopub.status.busy": "2023-05-17T17:47:59.699814Z",
     "iopub.status.idle": "2023-05-17T17:47:59.704716Z",
     "shell.execute_reply": "2023-05-17T17:47:59.703830Z"
    },
    "id": "-UdshNEtZfP6",
    "papermill": {
     "duration": 0.026666,
     "end_time": "2023-05-17T17:47:59.707063",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.680397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13874322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.746018Z",
     "iopub.status.busy": "2023-05-17T17:47:59.744982Z",
     "iopub.status.idle": "2023-05-17T17:47:59.750183Z",
     "shell.execute_reply": "2023-05-17T17:47:59.749339Z"
    },
    "id": "23rPhCQVxDbD",
    "papermill": {
     "duration": 0.027286,
     "end_time": "2023-05-17T17:47:59.752280",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.724994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977fccf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.790775Z",
     "iopub.status.busy": "2023-05-17T17:47:59.790444Z",
     "iopub.status.idle": "2023-05-17T17:47:59.794672Z",
     "shell.execute_reply": "2023-05-17T17:47:59.793705Z"
    },
    "id": "n7vZXeXbM2vg",
    "papermill": {
     "duration": 0.026131,
     "end_time": "2023-05-17T17:47:59.796891",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.770760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6478574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.833825Z",
     "iopub.status.busy": "2023-05-17T17:47:59.833502Z",
     "iopub.status.idle": "2023-05-17T17:47:59.837684Z",
     "shell.execute_reply": "2023-05-17T17:47:59.836832Z"
    },
    "papermill": {
     "duration": 0.025029,
     "end_time": "2023-05-17T17:47:59.839708",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.814679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfdfa3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.878826Z",
     "iopub.status.busy": "2023-05-17T17:47:59.877371Z",
     "iopub.status.idle": "2023-05-17T17:47:59.882296Z",
     "shell.execute_reply": "2023-05-17T17:47:59.881416Z"
    },
    "papermill": {
     "duration": 0.026359,
     "end_time": "2023-05-17T17:47:59.884342",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.857983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0adebca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:47:59.923232Z",
     "iopub.status.busy": "2023-05-17T17:47:59.922330Z",
     "iopub.status.idle": "2023-05-17T17:48:00.028917Z",
     "shell.execute_reply": "2023-05-17T17:48:00.027901Z"
    },
    "id": "FoIOPXi-3Cwf",
    "papermill": {
     "duration": 0.128238,
     "end_time": "2023-05-17T17:48:00.031267",
     "exception": false,
     "start_time": "2023-05-17T17:47:59.903029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c639ec3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:00.070190Z",
     "iopub.status.busy": "2023-05-17T17:48:00.069434Z",
     "iopub.status.idle": "2023-05-17T17:48:14.396950Z",
     "shell.execute_reply": "2023-05-17T17:48:14.395672Z"
    },
    "id": "R3mkNzoZxhX1",
    "outputId": "9cb2d757-3e4a-4f6d-bc4d-1f36701135c9",
    "papermill": {
     "duration": 14.350356,
     "end_time": "2023-05-17T17:48:14.400233",
     "exception": false,
     "start_time": "2023-05-17T17:48:00.049877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aaransia\r\n",
      "  Downloading aaransia-1.1.tar.gz (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from aaransia) (1.5.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from aaransia) (1.23.5)\r\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.10/site-packages (from aaransia) (1.3.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->aaransia) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->aaransia) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->aaransia) (1.16.0)\r\n",
      "Building wheels for collected packages: aaransia\r\n",
      "  Building wheel for aaransia (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aaransia: filename=aaransia-1.1-py3-none-any.whl size=45744 sha256=aa0890eea63755e126e0c9f7a5c0558f921931107e0bdc0b819418e5b0ccca43\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/d5/29/a98fd21f664d13c162b8fda3b2aa23a777b26377f23db60b03\r\n",
      "Successfully built aaransia\r\n",
      "Installing collected packages: aaransia\r\n",
      "Successfully installed aaransia-1.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aaransia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2937a438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.456088Z",
     "iopub.status.busy": "2023-05-17T17:48:14.455560Z",
     "iopub.status.idle": "2023-05-17T17:48:14.473331Z",
     "shell.execute_reply": "2023-05-17T17:48:14.472479Z"
    },
    "id": "ytdf6JRmxyKH",
    "papermill": {
     "duration": 0.048696,
     "end_time": "2023-05-17T17:48:14.476005",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.427309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aaransia import transliterate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f35caaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.531135Z",
     "iopub.status.busy": "2023-05-17T17:48:14.530781Z",
     "iopub.status.idle": "2023-05-17T17:48:14.550896Z",
     "shell.execute_reply": "2023-05-17T17:48:14.549868Z"
    },
    "id": "pPMEQElPU-8v",
    "papermill": {
     "duration": 0.050337,
     "end_time": "2023-05-17T17:48:14.553119",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.502782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pyarabic.araby import strip_tatweel,strip_tashkeel,normalize_ligature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d138d24",
   "metadata": {
    "id": "X1TXZ1V7Xi9w",
    "papermill": {
     "duration": 0.018737,
     "end_time": "2023-05-17T17:48:14.591187",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.572450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DATA EXPLORATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ee2804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.629904Z",
     "iopub.status.busy": "2023-05-17T17:48:14.628967Z",
     "iopub.status.idle": "2023-05-17T17:48:14.666146Z",
     "shell.execute_reply": "2023-05-17T17:48:14.665052Z"
    },
    "id": "Tq1zk8RvnsNZ",
    "papermill": {
     "duration": 0.059053,
     "end_time": "2023-05-17T17:48:14.668569",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.609516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('/kaggle/input/dataset-darija-1/dataset_darija_1.csv', on_bad_lines='skip', sep = ';')\n",
    "df.columns = ['sentiment','sentence']\n",
    "##df_2= pd.read_csv('/kaggle/input/dataset/dataset_darija_3.csv', on_bad_lines='skip', sep = ';',index_col=None)\n",
    "#df_2.columns = ['sentiment','sentence']\n",
    "#df=pd.concat([df_1, df_2], ignore_index=True, sort=False)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].str.replace(\" \", \"\")\n",
    "df['sentiment'] = df['sentiment'].str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab932a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.709278Z",
     "iopub.status.busy": "2023-05-17T17:48:14.708458Z",
     "iopub.status.idle": "2023-05-17T17:48:14.724083Z",
     "shell.execute_reply": "2023-05-17T17:48:14.722999Z"
    },
    "papermill": {
     "duration": 0.038687,
     "end_time": "2023-05-17T17:48:14.726463",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.687776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>neg</td>\n",
       "      <td>اصمت لعلى صمتك راحة بالنسبة لهم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>neg</td>\n",
       "      <td>حديقة حيوانات و لازال هنالك اناس لا يؤمنون بن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>neg</td>\n",
       "      <td>أفعى بجدارة تريثت تربصت و كان الفحيح متعة له ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>neg</td>\n",
       "      <td>لا يقطع الرأس غير الي ركبه الان اصبح تركيب ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>neg</td>\n",
       "      <td>امة النون نستنكر ندين نشجب ثم نوافق</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                           sentence\n",
       "2048       neg                   اصمت لعلى صمتك راحة بالنسبة لهم \n",
       "2049       neg   حديقة حيوانات و لازال هنالك اناس لا يؤمنون بن...\n",
       "2050       neg   أفعى بجدارة تريثت تربصت و كان الفحيح متعة له ...\n",
       "2051       neg   لا يقطع الرأس غير الي ركبه الان اصبح تركيب ال...\n",
       "2052       neg               امة النون نستنكر ندين نشجب ثم نوافق "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9602d3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.770813Z",
     "iopub.status.busy": "2023-05-17T17:48:14.770461Z",
     "iopub.status.idle": "2023-05-17T17:48:14.780463Z",
     "shell.execute_reply": "2023-05-17T17:48:14.779580Z"
    },
    "id": "ZdChFlXKVPe_",
    "papermill": {
     "duration": 0.033798,
     "end_time": "2023-05-17T17:48:14.782720",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.748922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df['sentiment']= le.fit_transform(df['sentiment'])\n",
    "df=df[df['sentiment']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "770fcc09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.823852Z",
     "iopub.status.busy": "2023-05-17T17:48:14.822976Z",
     "iopub.status.idle": "2023-05-17T17:48:14.836619Z",
     "shell.execute_reply": "2023-05-17T17:48:14.835593Z"
    },
    "id": "RH7j93JWKc-O",
    "outputId": "a71a034c-2ccd-45af-856b-39bf9b08d3c2",
    "papermill": {
     "duration": 0.036287,
     "end_time": "2023-05-17T17:48:14.838768",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.802481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1031\n",
       "0    1021\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e4258a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:14.880032Z",
     "iopub.status.busy": "2023-05-17T17:48:14.879712Z",
     "iopub.status.idle": "2023-05-17T17:48:15.111371Z",
     "shell.execute_reply": "2023-05-17T17:48:15.110431Z"
    },
    "id": "V95zLjaStMML",
    "outputId": "5329cc6c-327f-4032-c766-5ac5846da597",
    "papermill": {
     "duration": 0.255488,
     "end_time": "2023-05-17T17:48:15.113638",
     "exception": false,
     "start_time": "2023-05-17T17:48:14.858150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'sentiment')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df, x='sentiment')\n",
    "plt.xlabel('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e1abae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:15.159037Z",
     "iopub.status.busy": "2023-05-17T17:48:15.158147Z",
     "iopub.status.idle": "2023-05-17T17:48:15.163299Z",
     "shell.execute_reply": "2023-05-17T17:48:15.162395Z"
    },
    "id": "CbE5krsML4Zv",
    "papermill": {
     "duration": 0.03008,
     "end_time": "2023-05-17T17:48:15.165682",
     "exception": false,
     "start_time": "2023-05-17T17:48:15.135602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_values=[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4ad27",
   "metadata": {
    "id": "bPqnEt56WTWV",
    "papermill": {
     "duration": 0.020261,
     "end_time": "2023-05-17T17:48:15.206883",
     "exception": false,
     "start_time": "2023-05-17T17:48:15.186622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c2b43b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:15.249939Z",
     "iopub.status.busy": "2023-05-17T17:48:15.249537Z",
     "iopub.status.idle": "2023-05-17T17:48:24.355772Z",
     "shell.execute_reply": "2023-05-17T17:48:24.354793Z"
    },
    "id": "XcCrkdASP1xp",
    "outputId": "c9f1ad7c-556a-416f-ed63-2d966dd15881",
    "papermill": {
     "duration": 9.130816,
     "end_time": "2023-05-17T17:48:24.358519",
     "exception": false,
     "start_time": "2023-05-17T17:48:15.227703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293b54e9bda4408ead49ee9fe6e7693d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/307 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20e5f27a2f64013885377122158691d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b7c115ba74ababfe48dd6618b2575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/879k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75236b10b48a4dd78de2774ee08948ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9803c21dec5a446fb7d2f952ce5d3dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52765bda8604c76bfa38f699e462378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/836M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SI2M-Lab/DarijaBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DarijaBERT_tokenizer = AutoTokenizer.from_pretrained(\"SI2M-Lab/DarijaBERT\")\n",
    "DarijaBert_model = AutoModel.from_pretrained(\"SI2M-Lab/DarijaBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d343e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.402671Z",
     "iopub.status.busy": "2023-05-17T17:48:24.402321Z",
     "iopub.status.idle": "2023-05-17T17:48:24.407106Z",
     "shell.execute_reply": "2023-05-17T17:48:24.406088Z"
    },
    "id": "XVhyq3gfVtP6",
    "papermill": {
     "duration": 0.02924,
     "end_time": "2023-05-17T17:48:24.409501",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.380261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def repted(text):\n",
    "    text=re.sub(r'(.)\\1+', r'\\1', text)# Replace with only one (remove repetitions)  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaabc525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.454239Z",
     "iopub.status.busy": "2023-05-17T17:48:24.453960Z",
     "iopub.status.idle": "2023-05-17T17:48:24.460526Z",
     "shell.execute_reply": "2023-05-17T17:48:24.459571Z"
    },
    "id": "Bg5XoBaQZq_a",
    "papermill": {
     "duration": 0.031654,
     "end_time": "2023-05-17T17:48:24.462592",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.430938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_emojis():\n",
    "    with codecs.open(\"emoji.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "         positive_emoji=myfile.read()\n",
    "    positive_emoji=positive_emoji.split(\"\\r\\n\")\n",
    "    positive_emoji=positive_emoji[1:len(positive_emoji)-1] \n",
    "    with codecs.open(\"neg_emoji.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfie:\n",
    "        neg_emoji=myfie.read()\n",
    "    neg_emoji=neg_emoji.split(\"\\r\\n\")\n",
    "    neg_emoji=neg_emoji[1:len(neg_emoji)-1]\n",
    "    return positive_emoji,neg_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe69fbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.505116Z",
     "iopub.status.busy": "2023-05-17T17:48:24.504831Z",
     "iopub.status.idle": "2023-05-17T17:48:24.510647Z",
     "shell.execute_reply": "2023-05-17T17:48:24.509705Z"
    },
    "id": "JyduZn4EXUvB",
    "papermill": {
     "duration": 0.029252,
     "end_time": "2023-05-17T17:48:24.512675",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.483423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emoji_to_text(text):\n",
    "    text_words = []\n",
    "    words = text.split(\" \")\n",
    "    positive_emoji,neg_emoji=get_emojis()\n",
    "    for word in words:\n",
    "        if emoji_pattern.search(word):\n",
    "            if word in positive_emoji :\n",
    "                word='ايجابي'\n",
    "            if word in neg_emoji :\n",
    "                word='سلبي'\n",
    "        text_words.append(word)\n",
    "    return ' '.join(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b54d1ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.556295Z",
     "iopub.status.busy": "2023-05-17T17:48:24.554906Z",
     "iopub.status.idle": "2023-05-17T17:48:24.561718Z",
     "shell.execute_reply": "2023-05-17T17:48:24.560889Z"
    },
    "id": "mvftV-8c1iNY",
    "papermill": {
     "duration": 0.030383,
     "end_time": "2023-05-17T17:48:24.563645",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.533262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69c171df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.607609Z",
     "iopub.status.busy": "2023-05-17T17:48:24.606075Z",
     "iopub.status.idle": "2023-05-17T17:48:24.612614Z",
     "shell.execute_reply": "2023-05-17T17:48:24.611747Z"
    },
    "id": "qprNktz3Kxb2",
    "papermill": {
     "duration": 0.029828,
     "end_time": "2023-05-17T17:48:24.614571",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.584743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_links(text):\n",
    "    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n",
    "    links         = re.findall(link_regex, text)\n",
    "    for link in links:\n",
    "        text = text.replace(link[0], ', ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a0ad1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.659477Z",
     "iopub.status.busy": "2023-05-17T17:48:24.657834Z",
     "iopub.status.idle": "2023-05-17T17:48:24.666551Z",
     "shell.execute_reply": "2023-05-17T17:48:24.665734Z"
    },
    "id": "gjkLhvHKWQYC",
    "papermill": {
     "duration": 0.033471,
     "end_time": "2023-05-17T17:48:24.668765",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.635294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_processing(df,source,field):\n",
    "    df[field] = df[source]\n",
    "    df[field] = strip_links(df[field]) # remove links\n",
    "    df[field] = emoji_to_text(df[field]) # replace emojies with their sentiments\n",
    "    df[field] = df[field].replace(r'@[^\\s]+', 'USER', regex=True) # Replace user mentions with USER string\n",
    "    df[field] = df[field].replace(r'#[^\\s]+', 'HASHTAG', regex=True) # Replace Hashtags with HASHTAG string\n",
    "    df=df[df[field].apply(lambda x:len(re.findall(r'[\\u0600-\\u06FF]+', x)))>1] #Keep sequences with at least 2 arabic words\n",
    "    df[field] = df[field].apply(strip_tatweel) #Remove Tatweel string \n",
    "    df[field] = df[field].apply(strip_tashkeel) # Remove Diacritics\n",
    "    df[field] = df[field].apply(repted)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04b798c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.711763Z",
     "iopub.status.busy": "2023-05-17T17:48:24.711468Z",
     "iopub.status.idle": "2023-05-17T17:48:24.764637Z",
     "shell.execute_reply": "2023-05-17T17:48:24.763612Z"
    },
    "papermill": {
     "duration": 0.07774,
     "end_time": "2023-05-17T17:48:24.767076",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.689336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>طوال حياتي لم المس اي تغير حتى قدمت هذه الحكو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>هاذي بلاد الشرفاء و بلاد رجال لي دافعو على أرض...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>كل التوفيق بدر هاري ولد الشعب راك عزيز</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>كاتعجبني هاد أغنية 😎</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>يتبرع باموال باهضة لفقراء فخر المغرب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>0</td>\n",
       "      <td>اصمت لعلى صمتك راحة بالنسبة لهم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>0</td>\n",
       "      <td>حديقة حيوانات و لازال هنالك اناس لا يؤمنون بن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0</td>\n",
       "      <td>أفعى بجدارة تريثت تربصت و كان الفحيح متعة له ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>0</td>\n",
       "      <td>لا يقطع الرأس غير الي ركبه الان اصبح تركيب ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>0</td>\n",
       "      <td>امة النون نستنكر ندين نشجب ثم نوافق</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2052 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                           sentence\n",
       "0             1   طوال حياتي لم المس اي تغير حتى قدمت هذه الحكو...\n",
       "1             1  هاذي بلاد الشرفاء و بلاد رجال لي دافعو على أرض...\n",
       "2             1            كل التوفيق بدر هاري ولد الشعب راك عزيز \n",
       "3             1                              كاتعجبني هاد أغنية 😎 \n",
       "4             1              يتبرع باموال باهضة لفقراء فخر المغرب \n",
       "...         ...                                                ...\n",
       "2048          0                   اصمت لعلى صمتك راحة بالنسبة لهم \n",
       "2049          0   حديقة حيوانات و لازال هنالك اناس لا يؤمنون بن...\n",
       "2050          0   أفعى بجدارة تريثت تربصت و كان الفحيح متعة له ...\n",
       "2051          0   لا يقطع الرأس غير الي ركبه الان اصبح تركيب ال...\n",
       "2052          0               امة النون نستنكر ندين نشجب ثم نوافق \n",
       "\n",
       "[2052 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1=[]\n",
    "for sentence in df['sentence']:\n",
    "    sentence= strip_tatweel(sentence)\n",
    "    sentence= normalize_ligature(sentence)\n",
    "    sentence= repted(sentence)\n",
    "    sentence_1.append(sentence)\n",
    "df.drop(['sentence'], axis=1)   \n",
    "df.assign(sentence=sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f62ed5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.810927Z",
     "iopub.status.busy": "2023-05-17T17:48:24.810660Z",
     "iopub.status.idle": "2023-05-17T17:48:24.826479Z",
     "shell.execute_reply": "2023-05-17T17:48:24.825701Z"
    },
    "id": "2WcewrF2uMt7",
    "outputId": "f6d1dd52-3cb3-4ef0-9f1b-0456104fcde0",
    "papermill": {
     "duration": 0.039564,
     "end_time": "2023-05-17T17:48:24.828540",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.788976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: شحال زوينا دنيا\n",
      "   Tokens: ['شحال', 'زوينا', 'دنيا']\n",
      "Token IDs: [2448, 22504, 4236]\n"
     ]
    }
   ],
   "source": [
    "sample_txt= \"ch7al zwina dnia\"\n",
    "sample_txt_ar=transliterate(sample_txt, source='ma', target='ar', universal=True)\n",
    "tokens = DarijaBERT_tokenizer.tokenize(sample_txt_ar)\n",
    "token_ids = DarijaBERT_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(f' Sentence: {sample_txt_ar}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd8a354b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.871356Z",
     "iopub.status.busy": "2023-05-17T17:48:24.871098Z",
     "iopub.status.idle": "2023-05-17T17:48:24.882462Z",
     "shell.execute_reply": "2023-05-17T17:48:24.881586Z"
    },
    "id": "XSqLkzLY4cm6",
    "outputId": "d2014c09-6293-43dd-cd19-ccabe70d5793",
    "papermill": {
     "duration": 0.035067,
     "end_time": "2023-05-17T17:48:24.884344",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.849277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = DarijaBERT_tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  truncation=True,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28b5e68d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.928865Z",
     "iopub.status.busy": "2023-05-17T17:48:24.928010Z",
     "iopub.status.idle": "2023-05-17T17:48:24.940803Z",
     "shell.execute_reply": "2023-05-17T17:48:24.939822Z"
    },
    "id": "bXf9-iP1Bxrd",
    "outputId": "cd61208d-50b4-4137-d661-e3b1a9512ce4",
    "papermill": {
     "duration": 0.037089,
     "end_time": "2023-05-17T17:48:24.942749",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.905660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  8094,  1041,  3630, 56472,    48, 19829,  1058,     3,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bd55f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:24.987790Z",
     "iopub.status.busy": "2023-05-17T17:48:24.986855Z",
     "iopub.status.idle": "2023-05-17T17:48:26.355504Z",
     "shell.execute_reply": "2023-05-17T17:48:26.354428Z"
    },
    "id": "7HkSpvq-e-sh",
    "outputId": "f1a195a0-3387-47f8-a338-72cb0397f254",
    "papermill": {
     "duration": 1.39486,
     "end_time": "2023-05-17T17:48:26.359066",
     "exception": false,
     "start_time": "2023-05-17T17:48:24.964206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x797da30a3f40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_lens=[]\n",
    "\n",
    "for txt in df.sentence:\n",
    "  encodings=DarijaBERT_tokenizer.encode(txt,max_length=512)\n",
    "  var=length_hint(encodings)\n",
    "  token_lens.append(var)\n",
    "sns.displot(token_lens)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35727700",
   "metadata": {
    "id": "7O1DeyxF5jmd",
    "papermill": {
     "duration": 0.040884,
     "end_time": "2023-05-17T17:48:26.437480",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.396596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Creat a Pytorch Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "943dd129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:26.528646Z",
     "iopub.status.busy": "2023-05-17T17:48:26.528030Z",
     "iopub.status.idle": "2023-05-17T17:48:26.544464Z",
     "shell.execute_reply": "2023-05-17T17:48:26.543384Z"
    },
    "id": "-5YS2QvNtvsf",
    "papermill": {
     "duration": 0.063497,
     "end_time": "2023-05-17T17:48:26.547714",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.484217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GPSentenceDataset(Dataset):\n",
    "  def __init__(self, sentences, targets, tokenizer, max_len):\n",
    "    self.sentences = sentences\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  def __len__(self):\n",
    "    return len(self.sentences)\n",
    "  def __getitem__(self, item):\n",
    "    sentence = str(self.sentences[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      sentence,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
    "    attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n",
    "    return {\n",
    "      'sentence_text': sentence,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3602500b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:26.631990Z",
     "iopub.status.busy": "2023-05-17T17:48:26.631453Z",
     "iopub.status.idle": "2023-05-17T17:48:26.697424Z",
     "shell.execute_reply": "2023-05-17T17:48:26.696322Z"
    },
    "id": "hW0SnqAExK4X",
    "papermill": {
     "duration": 0.110715,
     "end_time": "2023-05-17T17:48:26.700604",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.589889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sentence in df.sentence:\n",
    "  sentence= remove_emojis(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e4708",
   "metadata": {
    "id": "vtJEk7YD2M-4",
    "papermill": {
     "duration": 0.04021,
     "end_time": "2023-05-17T17:48:26.782049",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.741839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**SPLIT THE DATASET**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dae4631f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:26.873442Z",
     "iopub.status.busy": "2023-05-17T17:48:26.872877Z",
     "iopub.status.idle": "2023-05-17T17:48:26.886773Z",
     "shell.execute_reply": "2023-05-17T17:48:26.885632Z"
    },
    "id": "9MJBXhUq2Rwa",
    "papermill": {
     "duration": 0.060456,
     "end_time": "2023-05-17T17:48:26.889845",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.829389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "  df,\n",
    "  test_size=0.1,\n",
    "  random_state=RANDOM_SEED\n",
    ")\n",
    "df_val, df_test = train_test_split(\n",
    "  df_test,\n",
    "  test_size=0.5,\n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd01ad",
   "metadata": {
    "id": "Atptran15zRZ",
    "papermill": {
     "duration": 0.04206,
     "end_time": "2023-05-17T17:48:26.975373",
     "exception": false,
     "start_time": "2023-05-17T17:48:26.933313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Creat Data Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142f890",
   "metadata": {
    "id": "j6Q8j2kfdgim",
    "papermill": {
     "duration": 0.041774,
     "end_time": "2023-05-17T17:48:27.058664",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.016890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15fe9363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.144584Z",
     "iopub.status.busy": "2023-05-17T17:48:27.143996Z",
     "iopub.status.idle": "2023-05-17T17:48:27.154403Z",
     "shell.execute_reply": "2023-05-17T17:48:27.153358Z"
    },
    "id": "YqMZggpm54IR",
    "papermill": {
     "duration": 0.057228,
     "end_time": "2023-05-17T17:48:27.157804",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.100576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPSentenceDataset(\n",
    "    sentences=df.sentence.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1ff1da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.242178Z",
     "iopub.status.busy": "2023-05-17T17:48:27.241721Z",
     "iopub.status.idle": "2023-05-17T17:48:27.253501Z",
     "shell.execute_reply": "2023-05-17T17:48:27.252596Z"
    },
    "id": "mKY7cT_Y6Sto",
    "papermill": {
     "duration": 0.057464,
     "end_time": "2023-05-17T17:48:27.256865",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.199401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 180\n",
    "train_data_loader = create_data_loader(df_train, DarijaBERT_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, DarijaBERT_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, DarijaBERT_tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10bd0d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.315335Z",
     "iopub.status.busy": "2023-05-17T17:48:27.315034Z",
     "iopub.status.idle": "2023-05-17T17:48:27.320184Z",
     "shell.execute_reply": "2023-05-17T17:48:27.319055Z"
    },
    "id": "zBqlD8RT9iWe",
    "papermill": {
     "duration": 0.031781,
     "end_time": "2023-05-17T17:48:27.322530",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.290749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = GPSentenceDataset(\n",
    "    sentences=df.sentence.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=DarijaBERT_tokenizer,\n",
    "    max_len=MAX_LEN\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc374bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.368988Z",
     "iopub.status.busy": "2023-05-17T17:48:27.368714Z",
     "iopub.status.idle": "2023-05-17T17:48:27.375722Z",
     "shell.execute_reply": "2023-05-17T17:48:27.374728Z"
    },
    "id": "eoT6ob5uGH6L",
    "outputId": "f612b4ab-aabc-439b-aa9d-abbefc9c44e5",
    "papermill": {
     "duration": 0.032347,
     "end_time": "2023-05-17T17:48:27.377812",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.345465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     int64\n",
       "sentence     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d23b8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.424428Z",
     "iopub.status.busy": "2023-05-17T17:48:27.424160Z",
     "iopub.status.idle": "2023-05-17T17:48:27.536257Z",
     "shell.execute_reply": "2023-05-17T17:48:27.535242Z"
    },
    "id": "nuXXfpqnCjm_",
    "outputId": "b0b43aeb-bf9d-434c-bdd0-ef10678419a1",
    "papermill": {
     "duration": 0.138089,
     "end_time": "2023-05-17T17:48:27.538523",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.400434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab082430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.586569Z",
     "iopub.status.busy": "2023-05-17T17:48:27.586237Z",
     "iopub.status.idle": "2023-05-17T17:48:27.591793Z",
     "shell.execute_reply": "2023-05-17T17:48:27.590848Z"
    },
    "id": "4m8g9ccMjWx7",
    "outputId": "a1f3aeb7-d660-4d02-9e76-27e582dc277e",
    "papermill": {
     "duration": 0.032301,
     "end_time": "2023-05-17T17:48:27.594033",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.561732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 180])\n",
      "torch.Size([16, 180])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3031aaa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.640744Z",
     "iopub.status.busy": "2023-05-17T17:48:27.640449Z",
     "iopub.status.idle": "2023-05-17T17:48:27.925686Z",
     "shell.execute_reply": "2023-05-17T17:48:27.924728Z"
    },
    "id": "wf4ZwPXTncB2",
    "papermill": {
     "duration": 0.311638,
     "end_time": "2023-05-17T17:48:27.928485",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.616847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_hidden_state, pooled_output = DarijaBert_model(\n",
    "  input_ids=encoding['input_ids'],\n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69677271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:27.977236Z",
     "iopub.status.busy": "2023-05-17T17:48:27.976409Z",
     "iopub.status.idle": "2023-05-17T17:48:27.984367Z",
     "shell.execute_reply": "2023-05-17T17:48:27.983425Z"
    },
    "id": "bTo5lMwEpnnS",
    "outputId": "ce60ea33-fcdc-4852-eb88-b19aafbd86e9",
    "papermill": {
     "duration": 0.034105,
     "end_time": "2023-05-17T17:48:27.986506",
     "exception": false,
     "start_time": "2023-05-17T17:48:27.952401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"SI2M-Lab/DarijaBERT\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"cls_token\": \"[CLS]\",\n",
       "  \"do_lower_case\": true,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"mask_token\": \"[MASK]\",\n",
       "  \"max_len\": 128,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_max_length\": 128,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token\": \"[PAD]\",\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"sep_token\": \"[SEP]\",\n",
       "  \"transformers_version\": \"4.28.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"unk_token\": \"[UNK]\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 80000\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DarijaBert_model.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34e205",
   "metadata": {
    "id": "hA-BjxX6stBv",
    "papermill": {
     "duration": 0.023178,
     "end_time": "2023-05-17T17:48:28.033035",
     "exception": false,
     "start_time": "2023-05-17T17:48:28.009857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Building a sentiment classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5636bbf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:28.080915Z",
     "iopub.status.busy": "2023-05-17T17:48:28.080601Z",
     "iopub.status.idle": "2023-05-17T17:48:28.088700Z",
     "shell.execute_reply": "2023-05-17T17:48:28.087619Z"
    },
    "id": "Pu3w1IKnst7Z",
    "papermill": {
     "duration": 0.034657,
     "end_time": "2023-05-17T17:48:28.090863",
     "exception": false,
     "start_time": "2023-05-17T17:48:28.056206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = DarijaBert_model = AutoModel.from_pretrained(\"SI2M-Lab/DarijaBERT\", return_dict=False)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    output = self.out(output)\n",
    "    return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3039e0f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:28.138944Z",
     "iopub.status.busy": "2023-05-17T17:48:28.138057Z",
     "iopub.status.idle": "2023-05-17T17:48:37.019907Z",
     "shell.execute_reply": "2023-05-17T17:48:37.018818Z"
    },
    "id": "l5U78sA7KplG",
    "outputId": "d0810213-e759-4f51-909f-b0fb22ad8bf6",
    "papermill": {
     "duration": 8.908502,
     "end_time": "2023-05-17T17:48:37.022723",
     "exception": false,
     "start_time": "2023-05-17T17:48:28.114221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of the model checkpoint at SI2M-Lab/DarijaBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(class_values))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "707184cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.073905Z",
     "iopub.status.busy": "2023-05-17T17:48:37.073510Z",
     "iopub.status.idle": "2023-05-17T17:48:37.080487Z",
     "shell.execute_reply": "2023-05-17T17:48:37.079200Z"
    },
    "id": "KhcFx02hMKKr",
    "outputId": "9610d38f-4929-47c0-b18e-94f49ab4d8c2",
    "papermill": {
     "duration": 0.035104,
     "end_time": "2023-05-17T17:48:37.082461",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.047357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 180])\n",
      "torch.Size([16, 180])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db8f13",
   "metadata": {
    "papermill": {
     "duration": 0.024145,
     "end_time": "2023-05-17T17:48:37.130939",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.106794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2297b25d",
   "metadata": {
    "papermill": {
     "duration": 0.025389,
     "end_time": "2023-05-17T17:48:37.182181",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.156792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56c6f5a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.231878Z",
     "iopub.status.busy": "2023-05-17T17:48:37.231515Z",
     "iopub.status.idle": "2023-05-17T17:48:37.243714Z",
     "shell.execute_reply": "2023-05-17T17:48:37.242418Z"
    },
    "papermill": {
     "duration": 0.039443,
     "end_time": "2023-05-17T17:48:37.245797",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.206354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "optimizer = AdamW(model.parameters(), lr=1e-8, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19538d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.295521Z",
     "iopub.status.busy": "2023-05-17T17:48:37.295209Z",
     "iopub.status.idle": "2023-05-17T17:48:37.304038Z",
     "shell.execute_reply": "2023-05-17T17:48:37.303111Z"
    },
    "papermill": {
     "duration": 0.036028,
     "end_time": "2023-05-17T17:48:37.306223",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.270195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  loss_fn,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "528f66cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.354289Z",
     "iopub.status.busy": "2023-05-17T17:48:37.354021Z",
     "iopub.status.idle": "2023-05-17T17:48:37.361137Z",
     "shell.execute_reply": "2023-05-17T17:48:37.360202Z"
    },
    "papermill": {
     "duration": 0.033177,
     "end_time": "2023-05-17T17:48:37.363122",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.329945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78749639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.409936Z",
     "iopub.status.busy": "2023-05-17T17:48:37.409677Z",
     "iopub.status.idle": "2023-05-17T17:48:37.413573Z",
     "shell.execute_reply": "2023-05-17T17:48:37.412735Z"
    },
    "papermill": {
     "duration": 0.02999,
     "end_time": "2023-05-17T17:48:37.415463",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.385473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d9d3514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.462776Z",
     "iopub.status.busy": "2023-05-17T17:48:37.462203Z",
     "iopub.status.idle": "2023-05-17T17:48:37.466578Z",
     "shell.execute_reply": "2023-05-17T17:48:37.465788Z"
    },
    "papermill": {
     "duration": 0.030567,
     "end_time": "2023-05-17T17:48:37.468702",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.438135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('best_model_state.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6655d375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T17:48:37.515906Z",
     "iopub.status.busy": "2023-05-17T17:48:37.515173Z",
     "iopub.status.idle": "2023-05-17T18:16:53.694978Z",
     "shell.execute_reply": "2023-05-17T18:16:53.693663Z"
    },
    "papermill": {
     "duration": 1696.205736,
     "end_time": "2023-05-17T18:16:53.697335",
     "exception": false,
     "start_time": "2023-05-17T17:48:37.491599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.700949859516374 accuracy 0.4826652221018418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.7056295020239693 accuracy 0.39805825242718446\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.699520880806035 accuracy 0.48212351029252437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.7038862364632743 accuracy 0.39805825242718446\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6956675160547783 accuracy 0.5075839653304441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.702542279447828 accuracy 0.4077669902912621\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6968438866837271 accuracy 0.5032502708559047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.7014334031513759 accuracy 0.39805825242718446\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6939170627758421 accuracy 0.5108342361863488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.7004815254892621 accuracy 0.4077669902912621\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.693919737791193 accuracy 0.5184182015167931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6996497000966754 accuracy 0.4077669902912621\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6955420842458462 accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6988865647997174 accuracy 0.39805825242718446\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6922877816290691 accuracy 0.5178764897074756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6981752429689679 accuracy 0.4174757281553398\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6909815191194929 accuracy 0.5222101841820151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6975331391607013 accuracy 0.4174757281553398\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6936779191781735 accuracy 0.513542795232936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6969206077711922 accuracy 0.4174757281553398\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6919629553268696 accuracy 0.5140845070422535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.69636584179742 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6928212272709814 accuracy 0.5157096424702058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6958529267992292 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6901415206235031 accuracy 0.5325027085590466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6954008681433541 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6917625639973015 accuracy 0.5216684723726976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6949635744094849 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6944897036100256 accuracy 0.5092091007583965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6945873584066119 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6928208711846121 accuracy 0.5075839653304441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6942245960235596 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6878624799950369 accuracy 0.5373781148429035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6938897967338562 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6898574161118475 accuracy 0.5216684723726976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.693576455116272 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6912066910801262 accuracy 0.5276273022751896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.693306062902723 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6877325223437671 accuracy 0.5249187432286023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6930628418922424 accuracy 0.42718446601941745\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6865992689954823 accuracy 0.5411700975081256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6928714939526149 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6914386019624513 accuracy 0.5352112676056338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6927009735788617 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6869984120130539 accuracy 0.5303358613217768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6925515277045113 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.687720118411656 accuracy 0.5444203683640303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6924338340759277 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6869334059542623 accuracy 0.5411700975081256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6923459683145795 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6888136976751787 accuracy 0.5433369447453954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6922824467931475 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6869098328310868 accuracy 0.5438786565547129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6922432439667838 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6883203315323797 accuracy 0.5276273022751896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6922226548194885 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6889406982167013 accuracy 0.5211267605633803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6922148891857692 accuracy 0.4368932038834951\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.6877593470030817 accuracy 0.5260021668472372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.6922136970928737 accuracy 0.4368932038834951\n",
      "\n",
      "CPU times: user 27min 20s, sys: 37.3 s, total: 27min 57s\n",
      "Wall time: 28min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(df_train)\n",
    "  )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_val)\n",
    "  )\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7528a468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:53.784324Z",
     "iopub.status.busy": "2023-05-17T18:16:53.783943Z",
     "iopub.status.idle": "2023-05-17T18:16:55.012602Z",
     "shell.execute_reply": "2023-05-17T18:16:55.011447Z"
    },
    "papermill": {
     "duration": 1.274322,
     "end_time": "2023-05-17T18:16:55.015144",
     "exception": false,
     "start_time": "2023-05-17T18:16:53.740822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4951456310679611"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15c7826a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:55.104816Z",
     "iopub.status.busy": "2023-05-17T18:16:55.103760Z",
     "iopub.status.idle": "2023-05-17T18:16:55.113174Z",
     "shell.execute_reply": "2023-05-17T18:16:55.112197Z"
    },
    "papermill": {
     "duration": 0.056182,
     "end_time": "2023-05-17T18:16:55.115469",
     "exception": false,
     "start_time": "2023-05-17T18:16:55.059287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"sentence_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "      real_values.extend(targets)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd12a825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:55.201175Z",
     "iopub.status.busy": "2023-05-17T18:16:55.200504Z",
     "iopub.status.idle": "2023-05-17T18:16:56.378660Z",
     "shell.execute_reply": "2023-05-17T18:16:56.377435Z"
    },
    "papermill": {
     "duration": 1.223738,
     "end_time": "2023-05-17T18:16:56.381290",
     "exception": false,
     "start_time": "2023-05-17T18:16:55.157552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_23/3943356482.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoding['input_ids'], dtype=torch.long)\n",
      "/tmp/ipykernel_23/3943356482.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(encoding['attention_mask'], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c3320be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:56.472406Z",
     "iopub.status.busy": "2023-05-17T18:16:56.472054Z",
     "iopub.status.idle": "2023-05-17T18:16:56.490371Z",
     "shell.execute_reply": "2023-05-17T18:16:56.489295Z"
    },
    "papermill": {
     "duration": 0.067087,
     "end_time": "2023-05-17T18:16:56.492974",
     "exception": false,
     "start_time": "2023-05-17T18:16:56.425887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    négative       0.41      0.19      0.26        48\n",
      "     positif       0.52      0.76      0.62        55\n",
      "\n",
      "    accuracy                           0.50       103\n",
      "   macro avg       0.46      0.48      0.44       103\n",
      "weighted avg       0.47      0.50      0.45       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['négative','positif']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b1eb527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:56.587286Z",
     "iopub.status.busy": "2023-05-17T18:16:56.586428Z",
     "iopub.status.idle": "2023-05-17T18:16:56.890409Z",
     "shell.execute_reply": "2023-05-17T18:16:56.889441Z"
    },
    "papermill": {
     "duration": 0.351697,
     "end_time": "2023-05-17T18:16:56.892460",
     "exception": false,
     "start_time": "2023-05-17T18:16:56.540763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment');\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=class_values, columns=['négative','positif'])\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b25891b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:56.979732Z",
     "iopub.status.busy": "2023-05-17T18:16:56.979420Z",
     "iopub.status.idle": "2023-05-17T18:16:56.987920Z",
     "shell.execute_reply": "2023-05-17T18:16:56.986934Z"
    },
    "papermill": {
     "duration": 0.054234,
     "end_time": "2023-05-17T18:16:56.990181",
     "exception": false,
     "start_time": "2023-05-17T18:16:56.935947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " أوقفوها و اريحونا من برامجها و الضرائب التي ندفعها لها ظلما و عدونا\n",
      "رغما عنا\n",
      "\n",
      "True sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "review_text = y_review_texts[idx]\n",
    "true_sentiment = y_test[idx]\n",
    "pred_df = pd.DataFrame({\n",
    "  'class_values': class_values,\n",
    "  'values': y_pred_probs[idx]\n",
    "})\n",
    "print(\"\\n\".join(wrap(review_text)))\n",
    "print()\n",
    "print(f'True sentiment: {class_values[true_sentiment]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd36c9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:57.077768Z",
     "iopub.status.busy": "2023-05-17T18:16:57.076848Z",
     "iopub.status.idle": "2023-05-17T18:16:57.084488Z",
     "shell.execute_reply": "2023-05-17T18:16:57.083533Z"
    },
    "papermill": {
     "duration": 0.054351,
     "end_time": "2023-05-17T18:16:57.086688",
     "exception": false,
     "start_time": "2023-05-17T18:16:57.032337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sample_txt= \"had lhotelat ma mori7inch\"\n",
    "sample_txt_ar=transliterate(sample_txt, source='ma', target='ar', universal=True)\n",
    "encoded_sentence = DarijaBERT_tokenizer.encode_plus(\n",
    "  sample_txt_ar,\n",
    "  max_length=MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bdbf98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T18:16:57.174848Z",
     "iopub.status.busy": "2023-05-17T18:16:57.173305Z",
     "iopub.status.idle": "2023-05-17T18:16:57.209803Z",
     "shell.execute_reply": "2023-05-17T18:16:57.208460Z"
    },
    "papermill": {
     "duration": 0.081734,
     "end_time": "2023-05-17T18:16:57.211839",
     "exception": false,
     "start_time": "2023-05-17T18:16:57.130105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: هاد لهوتلات ما موريحينش\n",
      "positif\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded_sentence['input_ids'].to(device)\n",
    "attention_mask = encoded_sentence['attention_mask'].to(device)\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "print(f'Review text: {sample_txt_ar}')\n",
    "if class_values[prediction]==1:\n",
    "    print('positif')\n",
    "else:\n",
    "    print('négatif')\n",
    "##print(f'Sentiment  : {class_values[prediction]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1792.0147,
   "end_time": "2023-05-17T18:17:00.202810",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-17T17:47:08.188110",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d95219f9da146ec9a91cf43712a0bf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_920709edc19b4856abba933d0022da7e",
       "placeholder": "​",
       "style": "IPY_MODEL_9ccc0293d1c7418d9fd6279e0f665156",
       "value": "Downloading (…)okenizer_config.json: 100%"
      }
     },
     "13c06c29aa12454fb38ccbbe66ada37b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c6d780c633641a69e5c66e0fa7620b5",
       "max": 779.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_919845f864664a2e9b07faf7fd1303cf",
       "value": 779.0
      }
     },
     "293b54e9bda4408ead49ee9fe6e7693d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0d95219f9da146ec9a91cf43712a0bf0",
        "IPY_MODEL_b99d6eecdc2f4b4aaeae9ff8549de7ac",
        "IPY_MODEL_e0faaaadd8844115a73c9f135b21bb23"
       ],
       "layout": "IPY_MODEL_cfc4184e92ff47c284b580de3ef068ce"
      }
     },
     "2da3d2b19d2f44cd8f3c2ba1a49d0b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "31a5523f96df47699cd4bcd6e52302bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "357859321e5547deb87f770291bc79fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38b1864ae5f84657a25bc6acc63a9c3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ac93edd40bf4f619119efb0b16b9203": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f90ce66e698940d399af3718bdfabef8",
       "placeholder": "​",
       "style": "IPY_MODEL_93e2405b357e430b9cc8d5a18a8146d1",
       "value": " 836M/836M [00:03&lt;00:00, 312MB/s]"
      }
     },
     "4112a73ad8514b21a006aba7872b8e1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbff1a15fad6400fbf1cec917fd43449",
       "placeholder": "​",
       "style": "IPY_MODEL_828cbff0d1074914ba150b7a9dff8fb0",
       "value": " 1.51M/1.51M [00:00&lt;00:00, 5.14MB/s]"
      }
     },
     "45447149cc0b41a38d6857a101dd82e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d082b0e9fc94e659b3f1ad54f20186c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5827ef0db734409fa26161042f83dd7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "593b7c115ba74ababfe48dd6618b2575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c72e144571a4469c8181c2a50207c1b0",
        "IPY_MODEL_62028a4ea33f462396526e4c67276037",
        "IPY_MODEL_5e14de357da64a2c8280a065179c2d9b"
       ],
       "layout": "IPY_MODEL_6c15b472126c4cd09a90b015845f1838"
      }
     },
     "5b111c0d5b1c48b6966239cd3395c433": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e14de357da64a2c8280a065179c2d9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b111c0d5b1c48b6966239cd3395c433",
       "placeholder": "​",
       "style": "IPY_MODEL_2da3d2b19d2f44cd8f3c2ba1a49d0b7f",
       "value": " 879k/879k [00:00&lt;00:00, 6.02MB/s]"
      }
     },
     "603a889a4f304046948b18e973c21bdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "60f8e0349191441b88c4021635cf793a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1438041771245c69bfbd29438065d2e",
       "placeholder": "​",
       "style": "IPY_MODEL_9f4d77a8afce431da087c6c3e2ff60cc",
       "value": " 779/779 [00:00&lt;00:00, 48.7kB/s]"
      }
     },
     "62028a4ea33f462396526e4c67276037": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5827ef0db734409fa26161042f83dd7c",
       "max": 878812.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7facaf17811741619dc3c97e8c736ece",
       "value": 878812.0
      }
     },
     "657e2f77918a4887994c91a994fc1546": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67441fd2ab104c5984af9ae554d0067c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67b2d49682ab4eb28c1c1df9e247eefd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "681aad6b749c4037b2d22457f713747c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9368f2e4e33405a8393d664862fdd21",
       "placeholder": "​",
       "style": "IPY_MODEL_a680be82fff6468f9506dc4c279e4dbe",
       "value": "Downloading (…)/main/tokenizer.json: 100%"
      }
     },
     "6b857b06d06b489b831aa20e7b32ed21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c15b472126c4cd09a90b015845f1838": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72db094470104d74b1119fe8c5089415": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75236b10b48a4dd78de2774ee08948ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_681aad6b749c4037b2d22457f713747c",
        "IPY_MODEL_fc9b2156884d4a65beb3c915f531d493",
        "IPY_MODEL_4112a73ad8514b21a006aba7872b8e1f"
       ],
       "layout": "IPY_MODEL_a7c953a0422e4c90bcc8dc6f175382af"
      }
     },
     "7bfaf0e3bf734e599b25d56023657987": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_72db094470104d74b1119fe8c5089415",
       "placeholder": "​",
       "style": "IPY_MODEL_91c7c0430efa42b88273f78494dc5b53",
       "value": "Downloading (…)cial_tokens_map.json: 100%"
      }
     },
     "7c6d780c633641a69e5c66e0fa7620b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7facaf17811741619dc3c97e8c736ece": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "828cbff0d1074914ba150b7a9dff8fb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "856e96dfff8942078e155d7653689f41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "919845f864664a2e9b07faf7fd1303cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "91c7c0430efa42b88273f78494dc5b53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "920709edc19b4856abba933d0022da7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "926fb060189947b798fd9ae981f5eea7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93e2405b357e430b9cc8d5a18a8146d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9803c21dec5a446fb7d2f952ce5d3dd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7bfaf0e3bf734e599b25d56023657987",
        "IPY_MODEL_e578b89d03d44416ba9b43ff38f53ef1",
        "IPY_MODEL_ce188d268e2f4cd09bd724c5275d8da2"
       ],
       "layout": "IPY_MODEL_856e96dfff8942078e155d7653689f41"
      }
     },
     "9bc9cca48ece4c45b75ab03c095b6782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c00a0a248c3d42c8ae63598aeb2c6221",
       "placeholder": "​",
       "style": "IPY_MODEL_67441fd2ab104c5984af9ae554d0067c",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "9c11d9959987461e9b0650724bc5883f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9ccc0293d1c7418d9fd6279e0f665156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9f4d77a8afce431da087c6c3e2ff60cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a1438041771245c69bfbd29438065d2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a20e5f27a2f64013885377122158691d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9bc9cca48ece4c45b75ab03c095b6782",
        "IPY_MODEL_13c06c29aa12454fb38ccbbe66ada37b",
        "IPY_MODEL_60f8e0349191441b88c4021635cf793a"
       ],
       "layout": "IPY_MODEL_6b857b06d06b489b831aa20e7b32ed21"
      }
     },
     "a680be82fff6468f9506dc4c279e4dbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a7c953a0422e4c90bcc8dc6f175382af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae62809ca57a4ff6b7dea786835b4c51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b29cb41cd3a14150a921540beef7b298": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae62809ca57a4ff6b7dea786835b4c51",
       "placeholder": "​",
       "style": "IPY_MODEL_fe45a1ef2d744a43b132122060ba26b3",
       "value": "Downloading pytorch_model.bin: 100%"
      }
     },
     "b52765bda8604c76bfa38f699e462378": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b29cb41cd3a14150a921540beef7b298",
        "IPY_MODEL_fd1db23698e84592bfceb68085e83488",
        "IPY_MODEL_3ac93edd40bf4f619119efb0b16b9203"
       ],
       "layout": "IPY_MODEL_cdaa69a08ba940afae19ff421f2fd902"
      }
     },
     "b99d6eecdc2f4b4aaeae9ff8549de7ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31a5523f96df47699cd4bcd6e52302bd",
       "max": 307.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45447149cc0b41a38d6857a101dd82e0",
       "value": 307.0
      }
     },
     "bbff1a15fad6400fbf1cec917fd43449": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beb96919084c489aae066f19c3f2b4bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c00a0a248c3d42c8ae63598aeb2c6221": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2e234b8cf8947bb93d10dabcf01f83a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c72e144571a4469c8181c2a50207c1b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_926fb060189947b798fd9ae981f5eea7",
       "placeholder": "​",
       "style": "IPY_MODEL_c2e234b8cf8947bb93d10dabcf01f83a",
       "value": "Downloading (…)solve/main/vocab.txt: 100%"
      }
     },
     "cdaa69a08ba940afae19ff421f2fd902": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce188d268e2f4cd09bd724c5275d8da2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e39efb33dfd54d94be4f64e98036a4b8",
       "placeholder": "​",
       "style": "IPY_MODEL_9c11d9959987461e9b0650724bc5883f",
       "value": " 112/112 [00:00&lt;00:00, 6.38kB/s]"
      }
     },
     "cfc4184e92ff47c284b580de3ef068ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0faaaadd8844115a73c9f135b21bb23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67b2d49682ab4eb28c1c1df9e247eefd",
       "placeholder": "​",
       "style": "IPY_MODEL_ee9b2b0425654cdda7da23d446a368d9",
       "value": " 307/307 [00:00&lt;00:00, 18.6kB/s]"
      }
     },
     "e39efb33dfd54d94be4f64e98036a4b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e578b89d03d44416ba9b43ff38f53ef1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_38b1864ae5f84657a25bc6acc63a9c3f",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d082b0e9fc94e659b3f1ad54f20186c",
       "value": 112.0
      }
     },
     "e9368f2e4e33405a8393d664862fdd21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee9b2b0425654cdda7da23d446a368d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f90ce66e698940d399af3718bdfabef8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc9b2156884d4a65beb3c915f531d493": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_357859321e5547deb87f770291bc79fc",
       "max": 1509195.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_beb96919084c489aae066f19c3f2b4bb",
       "value": 1509195.0
      }
     },
     "fd1db23698e84592bfceb68085e83488": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_657e2f77918a4887994c91a994fc1546",
       "max": 836400679.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_603a889a4f304046948b18e973c21bdc",
       "value": 836400679.0
      }
     },
     "fe45a1ef2d744a43b132122060ba26b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
